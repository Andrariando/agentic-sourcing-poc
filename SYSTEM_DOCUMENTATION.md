# Agentic Sourcing System: Technical Backend Documentation

This document provides a detailed technical deep-dive into the backend architecture and logic of the Agentic Sourcing Copilot. It is intended for auditing, technical review, and developers seeking to understand the inner workings of the system.

**Last Updated**: January 2026

---

## üèóÔ∏è 1. High-Level Architecture

The system follows a service-oriented architecture with a clear separation between governance, execution, and persistence.

- **API Layer (FastAPI)**: The entry point for all frontend requests (`backend/main.py`).
- **Service Layer (ChatService, CaseService)**: Orchestrates business logic and service interactions.
- **Agent Layer (Supervisor & Worker Agents)**: The "brain" of the system, using LLMs to analyze data and generate artifacts.
- **RAG Layer (Retriever, Vector Store)**: Handles document retrieval and grounding analysis.
- **Persistence Layer (SQLite/ChromaDB)**: Stores case data, chat history, and document embeddings.

### Running the System

```bash
# Terminal 1: Start Backend API
python -m uvicorn backend.main:app --port 8000

# Terminal 2: Start Frontend
python -m streamlit run frontend/app.py

# Seed Demo Data
python backend/scripts/seed_comprehensive_data.py
```

---

## üí¨ 2. The Chat Request Lifecycle

What happens when a human asks something in the chat window?

### Step 1: Frontend Submission
The user types a message and clicks send. The Streamlit frontend (`frontend/pages/case_copilot.py`) sends a `POST` request via `APIClient` to `/api/chat` with:
- `case_id`: The unique identifier for the current procurement project.
- `user_message`: The raw text input from the user.
- `use_tier_2`: A flag indicating whether to use more advanced (and expensive) LLM models.

### Step 2: ChatService Entry Point
`ChatService.process_message()` in `backend/services/chat_service.py` is the main orchestrator. It performs:
1. **Traceability**: Generates a unique `trace_id` (UUID) for logging and debugging this specific request.
2. **Context Retrieval**: Loads the current case state (DTP stage, status, metadata) from the database.
3. **Conversation Memory**: If enabled, fetches recent chat history to provide context to the LLM.

### Step 3: LLM-First Intent Analysis (LLMResponder)
Instead of rigid hard-coded rules, the system now uses a **LLM-First Strategy** (`backend/services/llm_responder.py`) to understand every user message:

1.  **Intent Classification**: The `LLMResponder` analyzes the user's message, conversation history, and case state to determine the intent.
    *   `needs_agent`: User wants to perform a task (e.g., "Score suppliers").
    *   `is_approval`/`is_rejection`: User is deciding on a recommendation.
    *   `needs_data`: User provided partial info, system needs to ask for more.
    *   `can_answer_directly`: User just asked a question (e.g., "What are the risks?") or wants to chat.

2.  **Dynamic Routing**:
    *   **Agent Execution**: If `needs_agent` is detected, the `ChatService` clears any "waiting" flags and routes to the LangGraph workflow.
    *   **Decision Processing**: If approval/rejection is detected, the system processes the decision and updates the stage.
    *   **Direct Response**: If the LLM can answer directly (using case context), it generates a response without running the full agent workflow.
    *   **Mixed Intents**: If the user asks a question *during* a pending approval (e.g. "What are the risks?"), the LLM answers the question AND gently reminds the user that a decision is still pending.

3.  **Natural Response Generation**:
    *   All responses are generated by the LLM (no templates).
    *   The LLM synthesizes the "Agent Output" (technical data) into a natural, friendly conversation.
    *   It maintains a consistent persona (helpful, professional copilot).

### Step 4: Agent Execution (LangGraph)
Once the path is chosen, the system executes the workflow:
1.  **Specialist Agent Node**: The selected agent (e.g., `StrategyAgent`) runs.
    *   It retrieves necessary data (SQL + RAG).
    *   It generates a structured artifact (e.g., `StrategyRecommendation`).
    *   **"Talk Back" Capability**: If the agent identifies missing data or risks, it can return an `AgentDialogue` object (e.g. "I need clarification") instead of a plan.
    *   It is **deterministic** in its calculations (e.g. scoring) but uses LLM for synthesis.
2.  **Loop**: The output is fed back to the Supervisor.
    *   **Success**: Output stored, stage advances.
    *   **Clarification Needed**: Supervisor routes to `CaseClarifier`.
    *   **Concern Raised**: Supervisor routes to `WaitForHuman`.

### Step 6: Persistence & State Update
The output and conversation history are saved:
- The `CaseService` persists the artifacts to the database.
- The `Case Status` might update (e.g., moving from "DTP-01" to "DTP-02").
- If the agent made a recommendation, the case state is set to `waiting_for_human = True`.

### Step 7: Natural Response Generation
The `LLMResponder` takes the agent's raw output (or direct answer) and formats it into a conversational message for the user. It ensures the tone is consistent and helpful, and seamlessly handles "Ask for more data" scenarios if the user's request was incomplete.

---

## üìä 3. DTP Stage Data Requirements

Each DTP (Draft to Procurement) stage uses specific data sources and produces specific outputs.

### DTP-01: Strategy (Need Identification)

**Purpose**: Identify sourcing opportunities and define initial strategy.

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Case Summary** | `CaseState` table | `case_id`, `category_id`, `trigger_source`, `status` |
| **Supplier Performance** | `SupplierPerformance` table | `supplier_id`, `overall_score`, `trend`, `risk_level` |
| **Spend Metrics** | `SpendMetric` table | `spend_amount`, `budget_amount`, `variance_percent` |
| **SLA Events** | `SLAEvent` table | `event_type`, `severity`, `sla_metric` |
| **Market Documents** | ChromaDB | `Market_Benchmark`, `Policy` documents |

**Agent**: `StrategyAgent` (`agents/strategy_agent.py`)
**Collaboration**: Supports dynamic user overrides (e.g. "Change strategy to X") to prioritize user intent over default rules.

**Output**: `StrategyRecommendation`
```python
class StrategyRecommendation:
    recommended_action: str  # "Renew", "Bid", "Monitor", "Terminate"
    confidence_score: float  # 0.0 to 1.0
    justification: str
    key_factors: List[str]
    risks: List[RiskItem]
```

**Sample Interaction**:
- User: "What's the renewal strategy for this case?"
- Agent: Queries supplier performance, spend trends, and SLA compliance to recommend action.

---

### DTP-02: Planning (Supplier Evaluation Prep)

**Purpose**: Prepare evaluation criteria and supplier longlist.

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Supplier Performance** | `SupplierPerformance` table | All performance scores (quality, delivery, responsiveness) |
| **Historical RFPs** | ChromaDB | Past RFP templates, evaluation criteria |
| **Market Benchmarks** | ChromaDB | Pricing benchmarks, typical SLAs |

**Agent**: `SupplierEvaluationAgent` (`agents/supplier_eval.py`)
**Collaboration**: Accepts user overrides for eligibility (e.g., "Include all suppliers", "Add Supplier X").

**Output**: `SupplierShortlist`
```python
class SupplierShortlist:
    shortlist: List[ShortlistEntry]  # Ranked suppliers with scores
    evaluation_criteria: Dict[str, float]  # Criteria weights
    methodology: str
```

---

### DTP-03: Sourcing (RFx & Selection)

**Purpose**: Issue RFx, collect responses, evaluate, and shortlist.

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Supplier Proposals** | Uploaded documents | Pricing, capabilities, references |
| **Evaluation Rubrics** | ChromaDB | Scoring criteria from policy docs |
| **Comparison Templates** | ChromaDB | Historical RFP evaluations |

**Agent**: `RfxDraftAgent` (in workflow)

**Output**: `RFxDraft` with evaluation matrices

---

### DTP-04: Negotiation

**Purpose**: Negotiate best terms with selected supplier(s).

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Market Rates** | ChromaDB | Benchmark pricing, typical increases |
| **Supplier History** | `SupplierPerformance` | Past performance, relationship strength |
| **Alternative Quotes** | Case context | Competitive pricing data |
| **BATNA Info** | ChromaDB | Best alternative options |

**Agent**: `NegotiationAgent` (`agents/negotiation.py`)
**Collaboration**: User can specify terms (e.g., "Net 60", "Focus on Price") which override default playbook strategies.

**Output**: `NegotiationPlan`
```python
class NegotiationPlan:
    leverage_points: List[str]
    target_terms: Dict[str, str]
    walkaway_position: str
    recommended_tactics: List[str]
```

**Sample Interaction**:
- User: "What's our negotiation position for this renewal?"
- Agent: Analyzes market benchmarks, alternative quotes, and relationship history.

---

### DTP-05: Contracting

**Purpose**: Finalize contract terms and prepare for signature.

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Contract Templates** | ChromaDB | Standard terms, legal clauses |
| **Negotiated Terms** | Previous outputs | Agreed pricing, SLAs |
| **Policy Requirements** | ChromaDB | Compliance checklist, approval gates |

**Agent**: `ContractSupportAgent`
**Collaboration**: Prioritizes user-requested clauses over standard templates.

**Output**: `ContractExtraction` with key terms and compliance status

---

### DTP-06: Implementation

**Purpose**: Execute, monitor, and capture value.

**Input Data Used**:
| Data Type | Source | Fields Used |
|-----------|--------|-------------|
| **Implementation Guides** | ChromaDB | Rollout best practices, timelines |
| **KPI Definitions** | Case context | Agreed metrics from contract |
| **Transition Plans** | ChromaDB | Change management docs |

**Agent**: `ImplementationAgent`
**Collaboration**: Allows modification of rollout steps (e.g. "Add Legal Review") via user intent.

**Output**: `ImplementationPlan` with milestones and KPIs

---

## üóÇÔ∏è 4. Synthetic Data Reference

The system comes with comprehensive synthetic data for testing. Run the seed script:

```bash
python backend/scripts/seed_comprehensive_data.py
```

### Available Test Cases

| Case ID | Name | Category | DTP Stage | Key Data |
|---------|------|----------|-----------|----------|
| CASE-0001 | IT Services Contract Renewal | IT_SERVICES | DTP-01 | 3 suppliers, 12mo spend, SLA history |
| CASE-0002 | Office Supplies Cost Reduction | OFFICE_SUPPLIES | DTP-01 | 3 suppliers, spend anomaly (+20%) |
| CASE-0003 | Cloud Infrastructure Migration | CLOUD_SERVICES | DTP-02 | AWS/Azure/GCP comparison data |
| CASE-0004 | Marketing Agency Selection | MARKETING_SERVICES | DTP-03 | 4 agency proposals, evaluation rubric |
| CASE-0005 | Facilities Management Negotiation | FACILITIES_MANAGEMENT | DTP-04 | Incumbent vs. market benchmarks |

### Supplier Data (16 suppliers across 5 categories)

**IT Services**:
- SUP-IT-001: TechCorp Solutions (7.8/10, stable, low risk)
- SUP-IT-002: Global IT Partners (7.2/10, improving, medium risk)
- SUP-IT-003: CloudFirst Systems (8.2/10, stable, low risk)

**Office Supplies**:
- SUP-OFF-001: OfficeMax Pro (7.0/10, declining, cost issues)
- SUP-OFF-002: Corporate Supply Co (8.0/10, competitive pricing)
- SUP-OFF-003: BulkOffice Direct (7.5/10, best pricing)

**Cloud Services**:
- SUP-CLOUD-001: Amazon Web Services (8.8/10)
- SUP-CLOUD-002: Microsoft Azure (8.7/10, better pricing)
- SUP-CLOUD-003: Google Cloud Platform (8.5/10, best pricing)

**Marketing Services**:
- SUP-MKT-001: Creative Minds Agency (8.3/10, premium)
- SUP-MKT-002: Digital First Marketing (8.0/10, improving)
- SUP-MKT-003: B2B Marketing Pros (7.8/10, value pricing)
- SUP-MKT-004: Integrated Brand Solutions (7.5/10)

**Facilities Management**:
- SUP-FAC-001: FacilityPro Services (8.5/10, requesting 8% increase)
- SUP-FAC-002: BuildingCare Plus (7.8/10, market rate)
- SUP-FAC-003: Integrated Facilities Group (7.5/10, competitive)

### Documents in ChromaDB (11 documents, 71 chunks)

| Document | Type | Category | DTP Relevance |
|----------|------|----------|---------------|
| RFP_Template_IT_Services.txt | RFx | IT_SERVICES | DTP-02, DTP-03 |
| IT_Services_Market_Benchmark_2025.txt | Market Report | IT_SERVICES | DTP-01, DTP-04 |
| Office_Supplies_Catalog_Pricing.txt | Catalog | OFFICE_SUPPLIES | DTP-01, DTP-02 |
| Office_Supplies_Market_Analysis.txt | Market Report | OFFICE_SUPPLIES | DTP-01, DTP-04 |
| Cloud_Provider_Comparison_Guide.txt | Technical Guide | CLOUD_SERVICES | DTP-01, DTP-02, DTP-03 |
| Cloud_Migration_Best_Practices.txt | Technical Guide | CLOUD_SERVICES | DTP-02, DTP-06 |
| Marketing_Agency_RFP_Template.txt | RFx | MARKETING_SERVICES | DTP-02, DTP-03 |
| Marketing_Agency_Evaluation_Rubric.txt | Evaluation Guide | MARKETING_SERVICES | DTP-03 |
| Facilities_Management_SOW.txt | Contract | FACILITIES_MANAGEMENT | DTP-05, DTP-06 |
| Facilities_Management_Market_Rates.txt | Market Report | FACILITIES_MANAGEMENT | DTP-01, DTP-04 |
| Procurement_Policy_DTP_Gates.txt | Policy | All | DTP-01 to DTP-06 |

---

## üõ†Ô∏è 5. Key Backend Components

### 1. ChatService (`backend/services/chat_service.py`)
The main orchestrator. Contains:
- `process_message()`: Primary API method (lines 121-251)
- Intent-specific handlers: `_handle_status_intent()`, `_handle_explain_intent()`, etc.
- Response formatting and error handling

**Important**: There is a legacy `process_message_langgraph()` method (lines 1009+) used by the standalone `app.py`. The API uses the first method.

### 2. The Supervisor Agent (`backend/supervisor/`)
The Supervisor is the hub. It manages the DTP workflow and ensures steps aren't skipped.

### 3. RAG Pipeline (`backend/rag/`)
- **Ingestion**: Documents are split into chunks and embedded into ChromaDB.
- **Retrieval**: Uses semantic search to find the top K most relevant chunks.
- **Grounding**: Agents provide "grounding source IDs" for citations.

### 4. Artifact Placement Map (`backend/artifacts/placement.py`)
Single source of truth for where data appears in the UI:
- `SIGNAL_REPORT` ‚Üí "Signals" tab
- `EVALUATION_SCORECARD` ‚Üí "Scoring" tab
- `RFX_DRAFT` ‚Üí "RFx" tab

### 5. Task-Based Agent Workflow (`backend/tasks/`)
Agents follow a structured **Task-Based** execution model:
1. **Task Registry**: Atomic tasks defined in `registry.py`
2. **Planners**: Determine task sequence
3. **Task Execution**: Each task has its own prompt and RAG context
4. **Task Feedback**: Results feed into the next task

### 5. LLMResponder (`backend/services/llm_responder.py`)
**[NEW]** The unified response handling service that replaces regex/template logic.
- **Intent Analysis**: Determines if user needs an agent, is approving, or just chatting.
- **Response Generation**: Generates all user-facing text.
- **Data Sufficiency**: Checks if user provided enough info; if not, generates natural follow-up questions.

---

## üõ°Ô∏è 6. Governance & Safety
- **Human-in-the-Loop**: All major decisions require explicit user approval.
- **Cost Awareness**: The `ConversationContextManager` prunes chat history.
- **Transparency**: Detailed execution metadata recorded for auditability.

---

## üîß 7. Recent Changes (January 2026)

### Collaborative Architecture Refactor
1.  **User Intent Injection**: All agents now accept `user_intent` to override deterministic rules/templates.
2.  **Refinement Loops**: The "Reject" decision in the workflow now triggers a **Feedback Loop** (Refinement) instead of termination. Users can provide a reason, and the agent re-runs with that context.
3.  **Platform Stability**: Fixed Windows-specific Unicode logging crashes.

### LLM-First Conversational Architecture
1.  **New `LLMResponder` Service** (`backend/services/llm_responder.py`): Replaces templated responses with dynamic LLM generation.
2.  **Smart Intent Classification**: Distinguishes QUESTIONS (answered directly) from ACTION REQUESTS (trigger agents).
3.  **Conversation Memory**: Context-aware responses using prior chat history.
4.  **Activity Logging**: All interactions (including direct responses) now logged for transparency.

### Bug Fixes
1. **Duplicate `process_message` method**: Renamed legacy method to `process_message_langgraph()` to prevent API issues.
2. **Pydantic/dict handling**: Fixed attribute access for `AgentActionLog` and `BudgetState` objects.
3. **Windows encoding**: Replaced emojis with ASCII-safe text in print statements.
4. **Backend emojis**: Fixed encoding issues in `backend/main.py` and `graphs/workflow.py`.
5. **Missing `_create_response`**: Added helper method for ChatResponse construction.
6. **UnboundLocalError**: Removed redundant local imports causing variable shadowing.
7. **Welcome message**: Fixed literal `\n` display using proper multiline strings.

### Data Enhancements
1. Created comprehensive seed script (`backend/scripts/seed_comprehensive_data.py`).
2. Added 5 realistic test cases across different categories and DTP stages.
3. Seeded 16 suppliers with differentiated performance data.
4. Added 11 category-specific documents to ChromaDB.

### Architecture Clarifications
- Frontend (`frontend/app.py`) communicates with backend API on port 8000.
- The root `app.py` is a legacy standalone version (not used with API architecture).

### Agent-Supervisor Dialogue ("Talking Back")
1.  **Bi-Directional Communication**: Agents can now return `AgentDialogue` objects to "talk back" to the Supervisor instead of strictly returning plans.
    *   `NeedClarification`: Routes to user for more info.
    *   `ConcernRaised`: Routes to human for safety check.
2.  **Separate Agent Logs**: Internal agent reasoning and dialogues are now displayed in a dedicated "üîç Agent Logs" panel in the frontend, keeping the main chat clean.
