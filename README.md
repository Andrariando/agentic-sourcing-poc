# Agentic Sourcing Copilot â€” Enterprise POC

A **human-in-the-loop, multi-agent decision-support system** for procurement sourcing, built on the Dynamic Transaction Pipeline (DTP-01 to DTP-06) methodology.

> **Current Version** â€” Procurement Workbench with 7 Official Agents & Artifact System

---

## ğŸ¯ Design Philosophy

| Principle | Implementation |
|-----------|----------------|
| **Decision is focal point** | AI advises, human decides |
| **Rules > LLM** | Deterministic rules before any LLM reasoning |
| **No autonomous decisions** | All recommendations require human approval |
| **Full traceability** | Every artifact grounded in data with verification status |
| **Grounded retrieval** | Answers cite uploaded documents/data |
| **Supervisor-only state changes** | Only Supervisor Agent can modify case state |

---

## ğŸ—ï¸ Architecture

### Official Agents (7 First-Class Modules)

1. **Supervisor Agent** â€” Orchestrates workflow, validates inputs, routes to agents
2. **Sourcing Signal Agent** â€” Monitors contracts, spend, performance for opportunities
3. **Supplier Scoring Agent** â€” Evaluates and ranks suppliers
4. **RFx Draft Agent** â€” Assembles RFx documents (RFI/RFP/RFQ)
5. **Negotiation Support Agent** â€” Provides negotiation insights (NO award decisions)
6. **Contract Support Agent** â€” Extracts terms, validates, prepares handoff
7. **Implementation Agent** â€” Rollout planning and value capture

### Folder Structure

```
agentic-sourcing-poc/
â”‚
â”œâ”€â”€ frontend/                    # Streamlit UI
â”‚   â”œâ”€â”€ app.py                   # Main entry point
â”‚   â”œâ”€â”€ api_client.py            # Backend communication
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ case_dashboard.py    # Case list & metrics
â”‚       â”œâ”€â”€ case_copilot.py      # Procurement Workbench
â”‚       â””â”€â”€ knowledge_management.py  # Document/data upload
â”‚
â”œâ”€â”€ backend/                     # All business logic
â”‚   â”œâ”€â”€ main.py                  # FastAPI server
â”‚   â”‚
â”‚   â”œâ”€â”€ supervisor/              # Central orchestration
â”‚   â”‚   â”œâ”€â”€ state.py             # State management
â”‚   â”‚   â””â”€â”€ router.py            # Two-level intent routing
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                  # Official agents (7 modules)
â”‚   â”‚   â”œâ”€â”€ base.py              # Base agent with retrieval
â”‚   â”‚   â”œâ”€â”€ supervisor_agent.py
â”‚   â”‚   â”œâ”€â”€ sourcing_signal_agent.py
â”‚   â”‚   â”œâ”€â”€ supplier_scoring_agent.py
â”‚   â”‚   â”œâ”€â”€ rfx_draft_agent.py
â”‚   â”‚   â”œâ”€â”€ negotiation_support_agent.py
â”‚   â”‚   â”œâ”€â”€ contract_support_agent.py
â”‚   â”‚   â””â”€â”€ implementation_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                   # Sub-tasks (internal to agents)
â”‚   â”‚   â”œâ”€â”€ base_task.py         # Task execution hierarchy
â”‚   â”‚   â”œâ”€â”€ registry.py          # Task registry
â”‚   â”‚   â”œâ”€â”€ planners.py          # Deterministic playbooks
â”‚   â”‚   â”œâ”€â”€ signal_tasks.py
â”‚   â”‚   â”œâ”€â”€ scoring_tasks.py
â”‚   â”‚   â”œâ”€â”€ rfx_tasks.py
â”‚   â”‚   â”œâ”€â”€ negotiation_tasks.py
â”‚   â”‚   â”œâ”€â”€ contract_tasks.py
â”‚   â”‚   â””â”€â”€ implementation_tasks.py
â”‚   â”‚
â”‚   â”œâ”€â”€ artifacts/               # Artifact builders & renderers
â”‚   â”‚   â”œâ”€â”€ builders.py          # ArtifactPack construction
â”‚   â”‚   â”œâ”€â”€ renderers.py         # UI formatting
â”‚   â”‚   â””â”€â”€ utils.py             # Grounding utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/               # Data ingestion pipelines
â”‚   â”‚   â”œâ”€â”€ document_ingest.py   # PDF/DOCX/TXT â†’ ChromaDB
â”‚   â”‚   â”œâ”€â”€ data_ingest.py       # CSV/Excel â†’ SQLite
â”‚   â”‚   â””â”€â”€ validators.py        # Schema validation
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                     # Vector retrieval
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ retriever.py         # Document retriever
â”‚   â”‚
â”‚   â”œâ”€â”€ persistence/             # Data lake
â”‚   â”‚   â”œâ”€â”€ database.py          # SQLite connection
â”‚   â”‚   â””â”€â”€ models.py            # SQLModel tables (includes Artifact)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic layer
â”‚   â”‚   â”œâ”€â”€ case_service.py      # Case + artifact management
â”‚   â”‚   â”œâ”€â”€ chat_service.py      # Copilot with Supervisor
â”‚   â”‚   â””â”€â”€ ingestion_service.py # Ingestion orchestration
â”‚   â”‚
â”‚   â””â”€â”€ scripts/                 # Utility scripts
â”‚       â””â”€â”€ seed_synthetic_data.py  # Happy Path demo data
â”‚
â”œâ”€â”€ shared/                      # Cross-cutting modules
â”‚   â”œâ”€â”€ schemas.py               # Pydantic schemas (ArtifactPack, etc.)
â”‚   â””â”€â”€ constants.py             # Enums (AgentName, ArtifactType, etc.)
â”‚
â””â”€â”€ data/                        # Synthetic data & databases
    â”œâ”€â”€ datalake.db              # SQLite data lake
    â”œâ”€â”€ chroma_db/               # ChromaDB vector store
    â”œâ”€â”€ synthetic/                # Synthetic data files
    â””â”€â”€ synthetic_docs/           # Sample documents for RAG
```

### System Flow

```
User Message â†’ Supervisor (Intent Classification)
                â†“
         ActionPlan (agent + tasks)
                â†“
         Agent Execution (tasks â†’ ArtifactPack)
                â†“
         Persist Artifacts â†’ Update State (Supervisor only)
                â†“
         UI: Procurement Workbench (Artifacts + Next Actions)
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API key

### Installation

```bash
# Clone repository
git clone https://github.com/Andrariando/agentic-sourcing-poc.git
cd agentic-sourcing-poc

# Install dependencies
pip install -r requirements.txt

# Create .env file
echo "OPENAI_API_KEY=your-key-here" > .env
```

### Running Locally

```bash
# Terminal 1: Start Backend
python -m uvicorn backend.main:app --reload --port 8000

# Terminal 2: Start Frontend
streamlit run frontend/app.py
```

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Frontend**: http://localhost:8501

### Seed Synthetic Data (Happy Path Demo)

```bash
# Seed CASE-0001 and sample data
python backend/scripts/seed_synthetic_data.py
```

This creates:
- **CASE-0001** â€” IT Services Contract Renewal
- Supplier performance data (3 suppliers)
- Spend data with anomalies
- SLA events
- Sample documents in ChromaDB

---

## ğŸ® Happy Path Demo Sequence

Open **CASE-0001** in the Procurement Workbench and run:

1. **"Scan signals"** â†’ Signal Report with urgency score + recommendations
2. **"Score suppliers"** â†’ Supplier Scorecard + Shortlist (SUP-001 ranked #1)
3. **"Draft RFx"** â†’ RFx Draft Pack + Q&A Tracker
4. **"Support negotiation"** â†’ Negotiation Plan + Leverage Points + Targets
5. **"Extract key terms"** â†’ Key Terms Extract + Validation Report + Handoff Packet
6. **"Generate implementation plan"** â†’ Implementation Checklist + Early Indicators + Value Capture

Each step produces **ArtifactPacks** with:
- Multiple artifacts (reports, scorecards, drafts)
- Next best actions
- Risk items
- Grounding references (doc IDs, data sources)

---

## ğŸ“¡ API Reference

### Case Management
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/cases` | List all cases |
| GET | `/api/cases/{id}` | Get case details |
| POST | `/api/cases` | Create new case |

### Copilot Chat
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat` | Send message to copilot (returns ArtifactPack) |

### Human Decisions
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/decisions/approve` | Approve recommendation |
| POST | `/api/decisions/reject` | Reject recommendation |

### Document Ingestion (RAG)
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/ingest/document` | Upload PDF/DOCX/TXT |
| GET | `/api/documents` | List ingested documents |
| DELETE | `/api/documents/{id}` | Delete document |

### Structured Data Ingestion
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/ingest/data/preview` | Preview CSV/Excel |
| POST | `/api/ingest/data` | Ingest to data lake |
| GET | `/api/ingest/history` | View ingestion history |

### System
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |

---

## ğŸ” Governance Rules

1. **Supervisor is ONLY component that writes case state** â€” All other agents return outputs only
2. **Decision logic hierarchy** â€” Rules â†’ Retrieval â†’ Analytics â†’ LLM (in that order)
3. **Human approval required** â€” For any DECIDE-type recommendation or stage change
4. **Traceability** â€” Every artifact includes `grounded_in` references; missing = UNVERIFIED
5. **Two-level intent routing** â€” (UserGoal, WorkType) â†’ Agent + Tasks
6. **Artifact persistence** â€” All agent outputs saved as ArtifactPacks with verification status

---

## ğŸ¨ UI Design

**Procurement Workbench** â€” Three-panel layout:

- **Top Panel**: Next Best Actions (stage-specific quick actions)
- **Left Panel**: Artifacts (tabs: Signals, Scoring, RFx, Negotiation, Contract, Implementation, History)
- **Center Panel**: Chat Copilot (conversational interface)
- **Right Panel**: Governance (stage, status, approval controls)

MIT color system:
- **MIT Navy** (`#003A8F`) â€” Headers, structure
- **MIT Cardinal Red** (`#A31F34`) â€” Actions, alerts
- **Near Black** (`#1F1F1F`) â€” Body text
- **Charcoal** (`#4A4A4A`) â€” Secondary text

---

## ğŸ“¦ Artifact System

Agents produce **ArtifactPacks** containing:

- **Artifacts** â€” Work products (reports, scorecards, drafts, checklists)
- **Next Actions** â€” Recommended next steps with rationale
- **Risks** â€” Identified risks with mitigation
- **Grounding** â€” References to source documents/data
- **Verification Status** â€” VERIFIED, PARTIAL, or UNVERIFIED

Artifact types include:
- `SIGNAL_REPORT`, `SUPPLIER_SCORECARD`, `RFX_DRAFT_PACK`
- `NEGOTIATION_PLAN`, `KEY_TERMS_EXTRACT`, `IMPLEMENTATION_CHECKLIST`
- And more (see `shared/constants.py` for full list)

---

## ğŸ§ª Task System

Each agent has **sub-tasks** that follow the decision hierarchy:

1. **run_rules()** â€” Deterministic policy checks
2. **run_retrieval()** â€” ChromaDB + SQLite data retrieval
3. **run_analytics()** â€” Scoring, normalization, comparison
4. **run_llm()** â€” Narrative generation (only if needed)

Tasks are **internal to agents** and not exposed separately in UI.

---

## ğŸ“ Data

Synthetic test data:
- **CASE-0001** â€” IT Services contract renewal scenario
- **3 Suppliers** â€” Performance data with differentiation
- **12 months spend** â€” With anomaly detection
- **SLA events** â€” Supplier performance issues
- **Sample documents** â€” RFP template, benchmarks, policy, contract terms

Seed via: `python backend/scripts/seed_synthetic_data.py`

---

## âš ï¸ Notes

- **Research POC** â€” Not production-ready
- **Synthetic data** â€” All metrics are illustrative
- **No authentication** â€” Add API keys for production
- **Backward compatible** â€” Legacy agents still work alongside new system

---

## ğŸ“œ License

Research POC â€” Not for production use

---

## ğŸ› ï¸ Development Status

| Component | Status |
|-----------|--------|
| 7 Official Agents | âœ… Complete |
| Task System | âœ… Complete |
| Artifact System | âœ… Complete |
| Procurement Workbench UI | âœ… Complete |
| Synthetic Data & Demo | âœ… Complete |
| Production Hardening | ğŸ”œ Planned |
