# Agentic Sourcing Copilot â€” Enterprise POC

A **human-in-the-loop, multi-agent decision-support system** for procurement sourcing, built on the Dynamic Transaction Pipeline (DTP-01 to DTP-06) methodology.

> **Current Version** â€” Procurement Workbench with 7 Official Agents & Artifact System

---

## ğŸ¯ Design Philosophy

| Principle | Implementation |
|-----------|----------------|
| **Decision is focal point** | AI advises, human decides |
| **Rules > LLM** | Deterministic rules before any LLM reasoning |
| **No autonomous decisions** | All recommendations require human approval |
| **Full traceability** | Every artifact grounded in data with verification status |
| **Grounded retrieval** | Answers cite uploaded documents/data |
| **Supervisor-only state changes** | Only Supervisor Agent can modify case state |

---

## ğŸ—ï¸ Architecture

### Official Agents (7 First-Class Modules)

1. **Supervisor Agent** â€” Orchestrates workflow, validates inputs, routes to agents
2. **Sourcing Signal Agent** â€” Monitors contracts, spend, performance for opportunities
3. **Supplier Scoring Agent** â€” Evaluates and ranks suppliers
4. **RFx Draft Agent** â€” Assembles RFx documents (RFI/RFP/RFQ)
5. **Negotiation Support Agent** â€” Provides negotiation insights (NO award decisions)
6. **Contract Support Agent** â€” Extracts terms, validates, prepares handoff
7. **Implementation Agent** â€” Rollout planning and value capture

### Folder Structure

```
agentic-sourcing-poc/
â”‚
â”œâ”€â”€ frontend/                    # Streamlit UI
â”‚   â”œâ”€â”€ app.py                   # Main entry point
â”‚   â”œâ”€â”€ api_client.py            # Backend communication
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ case_dashboard.py    # Case list & metrics
â”‚       â”œâ”€â”€ case_copilot.py      # Procurement Workbench
â”‚       â””â”€â”€ knowledge_management.py  # Document/data upload
â”‚
â”œâ”€â”€ backend/                     # All business logic
â”‚   â”œâ”€â”€ main.py                  # FastAPI server
â”‚   â”‚
â”‚   â”œâ”€â”€ supervisor/              # Central orchestration
â”‚   â”‚   â”œâ”€â”€ state.py             # State management
â”‚   â”‚   â””â”€â”€ router.py            # Two-level intent routing
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                  # Official agents (7 modules)
â”‚   â”‚   â”œâ”€â”€ base.py              # Base agent with retrieval
â”‚   â”‚   â”œâ”€â”€ supervisor_agent.py
â”‚   â”‚   â”œâ”€â”€ sourcing_signal_agent.py
â”‚   â”‚   â”œâ”€â”€ supplier_scoring_agent.py
â”‚   â”‚   â”œâ”€â”€ rfx_draft_agent.py
â”‚   â”‚   â”œâ”€â”€ negotiation_support_agent.py
â”‚   â”‚   â”œâ”€â”€ contract_support_agent.py
â”‚   â”‚   â””â”€â”€ implementation_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                   # Sub-tasks (internal to agents)
â”‚   â”‚   â”œâ”€â”€ base_task.py         # Task execution hierarchy
â”‚   â”‚   â”œâ”€â”€ registry.py          # Task registry
â”‚   â”‚   â”œâ”€â”€ planners.py          # Deterministic playbooks
â”‚   â”‚   â”œâ”€â”€ signal_tasks.py
â”‚   â”‚   â”œâ”€â”€ scoring_tasks.py
â”‚   â”‚   â”œâ”€â”€ rfx_tasks.py
â”‚   â”‚   â”œâ”€â”€ negotiation_tasks.py
â”‚   â”‚   â”œâ”€â”€ contract_tasks.py
â”‚   â”‚   â””â”€â”€ implementation_tasks.py
â”‚   â”‚
â”‚   â”œâ”€â”€ artifacts/               # Artifact builders & renderers
â”‚   â”‚   â”œâ”€â”€ builders.py          # ArtifactPack construction
â”‚   â”‚   â”œâ”€â”€ renderers.py         # UI formatting
â”‚   â”‚   â””â”€â”€ utils.py             # Grounding utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/               # Data ingestion pipelines
â”‚   â”‚   â”œâ”€â”€ document_ingest.py   # PDF/DOCX/TXT â†’ ChromaDB
â”‚   â”‚   â”œâ”€â”€ data_ingest.py       # CSV/Excel â†’ SQLite
â”‚   â”‚   â””â”€â”€ validators.py        # Schema validation
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                     # Vector retrieval
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ retriever.py         # Document retriever
â”‚   â”‚
â”‚   â”œâ”€â”€ persistence/             # Data lake
â”‚   â”‚   â”œâ”€â”€ database.py          # SQLite connection
â”‚   â”‚   â””â”€â”€ models.py            # SQLModel tables (includes Artifact)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic layer
â”‚   â”‚   â”œâ”€â”€ case_service.py      # Case + artifact management
â”‚   â”‚   â”œâ”€â”€ chat_service.py      # Copilot with Supervisor
â”‚   â”‚   â””â”€â”€ ingestion_service.py # Ingestion orchestration
â”‚   â”‚
â”‚   â””â”€â”€ scripts/                 # Utility scripts
â”‚       â””â”€â”€ seed_synthetic_data.py  # Happy Path demo data
â”‚
â”œâ”€â”€ shared/                      # Cross-cutting modules
â”‚   â”œâ”€â”€ schemas.py               # Pydantic schemas (ArtifactPack, etc.)
â”‚   â””â”€â”€ constants.py             # Enums (AgentName, ArtifactType, etc.)
â”‚
â””â”€â”€ data/                        # Synthetic data & databases
    â”œâ”€â”€ datalake.db              # SQLite data lake
    â”œâ”€â”€ chroma_db/               # ChromaDB vector store
    â”œâ”€â”€ synthetic/                # Synthetic data files
    â””â”€â”€ synthetic_docs/           # Sample documents for RAG
```

### System Flow

```
User Message â†’ Supervisor (Intent Classification)
                â†“
         ActionPlan (agent + tasks)
                â†“
         Agent Execution (tasks â†’ ArtifactPack)
                â†“
         Persist Artifacts â†’ Update State (Supervisor only)
                â†“
         UI: Procurement Workbench (Artifacts + Next Actions)
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API key

### Installation

```bash
# Clone repository
git clone https://github.com/Andrariando/agentic-sourcing-poc.git
cd agentic-sourcing-poc

# Install dependencies
pip install -r requirements.txt

# Create .env file
echo "OPENAI_API_KEY=your-key-here" > .env
```

### Running Locally

```bash
# Terminal 1: Start Backend
python -m uvicorn backend.main:app --reload --port 8000

# Terminal 2: Start Frontend
streamlit run frontend/app.py
```

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Frontend**: http://localhost:8501

### Seed Synthetic Data (Happy Path Demo)

```bash
# Seed CASE-0001 and sample data
python backend/scripts/seed_synthetic_data.py
```

This creates:
- **CASE-0001** â€” IT Services Contract Renewal
- Supplier performance data (3 suppliers)
- Spend data with anomalies
- SLA events
- Sample documents in ChromaDB

---

## ğŸ® Happy Path Demo Sequence

Open **CASE-0001** in the Procurement Workbench and run:

1. **"Scan signals"** â†’ Signal Report with urgency score + recommendations
2. **"Score suppliers"** â†’ Supplier Scorecard + Shortlist (SUP-001 ranked #1)
3. **"Draft RFx"** â†’ RFx Draft Pack + Q&A Tracker
4. **"Support negotiation"** â†’ Negotiation Plan + Leverage Points + Targets
5. **"Extract key terms"** â†’ Key Terms Extract + Validation Report + Handoff Packet
6. **"Generate implementation plan"** â†’ Implementation Checklist + Early Indicators + Value Capture

Each step produces **ArtifactPacks** with:
- Multiple artifacts (reports, scorecards, drafts)
- Next best actions
- Risk items
- Grounding references (doc IDs, data sources)

---

## ğŸ“¡ API Reference

### Case Management
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/cases` | List all cases |
| GET | `/api/cases/{id}` | Get case details |
| POST | `/api/cases` | Create new case |

### Copilot Chat
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat` | Send message to copilot (returns ArtifactPack) |

### Human Decisions
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/decisions/approve` | Approve recommendation |
| POST | `/api/decisions/reject` | Reject recommendation |

### Document Ingestion (RAG)
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/ingest/document` | Upload PDF/DOCX/TXT |
| GET | `/api/documents` | List ingested documents |
| DELETE | `/api/documents/{id}` | Delete document |

### Structured Data Ingestion
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/ingest/data/preview` | Preview CSV/Excel |
| POST | `/api/ingest/data` | Ingest to data lake |
| GET | `/api/ingest/history` | View ingestion history |

### System
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |

---

## ğŸ” Governance Rules

1. **Supervisor is ONLY component that writes case state** â€” All other agents return outputs only
2. **Decision logic hierarchy** â€” Rules â†’ Retrieval â†’ Analytics â†’ LLM (in that order)
3. **Human approval required** â€” For any DECIDE-type recommendation or stage change
4. **Traceability** â€” Every artifact includes `grounded_in` references; missing = UNVERIFIED
5. **Two-level intent routing** â€” (UserGoal, WorkType) â†’ Agent + Tasks
6. **Artifact persistence** â€” All agent outputs saved as ArtifactPacks with verification status

---

## ğŸ¨ UI Design

**Procurement Workbench** â€” Three-panel layout:

- **Top Panel**: Next Best Actions (stage-specific quick actions)
- **Left Panel**: Artifacts (tabs: Signals, Scoring, RFx, Negotiation, Contract, Implementation, History)
- **Center Panel**: Chat Copilot (conversational interface)
- **Right Panel**: Governance (stage, status, approval controls)

MIT color system:
- **MIT Navy** (`#003A8F`) â€” Headers, structure
- **MIT Cardinal Red** (`#A31F34`) â€” Actions, alerts
- **Near Black** (`#1F1F1F`) â€” Body text
- **Charcoal** (`#4A4A4A`) â€” Secondary text

---

## ğŸ“¦ Artifact System

Agents produce **ArtifactPacks** containing:

- **Artifacts** â€” Work products (reports, scorecards, drafts, checklists)
- **Next Actions** â€” Recommended next steps with rationale
- **Risks** â€” Identified risks with mitigation
- **Grounding** â€” References to source documents/data
- **Verification Status** â€” VERIFIED, PARTIAL, or UNVERIFIED

Artifact types include:
- `SIGNAL_REPORT`, `SUPPLIER_SCORECARD`, `RFX_DRAFT_PACK`
- `NEGOTIATION_PLAN`, `KEY_TERMS_EXTRACT`, `IMPLEMENTATION_CHECKLIST`
- And more (see `shared/constants.py` for full list)

---

## ğŸ§ª Task System

Each agent has **sub-tasks** that follow the decision hierarchy:

1. **run_rules()** â€” Deterministic policy checks
2. **run_retrieval()** â€” ChromaDB + SQLite data retrieval
3. **run_analytics()** â€” Scoring, normalization, comparison
4. **run_llm()** â€” Narrative generation (only if needed)

Tasks are **internal to agents** and not exposed separately in UI.

---

## ğŸ¤– Agent Details & Sub-Tasks

### 1. Supervisor Agent

**Purpose**: Orchestrates workflow, validates inputs, selects sourcing pathway, routes to downstream agents.

**Key Responsibilities**:
- Two-level intent classification (UserGoal, WorkType)
- Stage transition validation
- Required input validation
- Agent and task routing
- Human checkpoint enforcement
- **ONLY component allowed to write case state**

**Sub-Tasks**:
1. **`classify_intent_two_level`** â€” Classifies user message into (UserGoal, WorkType) using pattern matching
2. **`validate_stage_transition`** â€” Checks if requested action is allowed at current DTP stage
3. **`validate_required_inputs`** â€” Verifies all required data is present (category, supplier, contract, etc.)
4. **`select_sourcing_pathway`** â€” Determines sourcing approach (strategic, competitive, simplified) based on rules
5. **`route_agent_and_tasks`** â€” Creates ActionPlan with agent name and ordered task list
6. **`enforce_human_checkpoints`** â€” Determines if approval is required
7. **`update_state_and_log`** â€” Updates case state (dtp_stage, status, waiting_for_human) and activity log

**Outputs**:
- `STATUS_SUMMARY` artifact
- `NEXT_BEST_ACTIONS` artifact
- `ActionPlan` (internal)

**Analytical Logic**: Heuristic routing rules, context memory, retrieval of procedural references/playbooks.

---

### 2. Sourcing Signal Agent

**Purpose**: Monitors contract metadata, spend patterns, supplier performance, and approved external signals to proactively identify sourcing cases.

**Key Responsibilities**:
- Detect contract expiry signals
- Identify performance degradation
- Flag spend anomalies
- Apply relevance filters
- Generate autoprep recommendations

**Sub-Tasks**:
1. **`detect_contract_expiry_signals`** â€” Queries SQLite contracts table for expiring contracts (30-90 day window)
2. **`detect_performance_degradation_signals`** â€” Analyzes supplier performance trends for declining scores or high risk
3. **`detect_spend_anomalies`** â€” Statistical deviation analysis on spend patterns (2+ standard deviations)
4. **`apply_relevance_filters`** â€” Filters signals by category, DTP stage, and severity
5. **`semantic_grounded_summary`** â€” LLM narration of signals (only after retrieval/analytics)
6. **`produce_autoprep_recommendations`** â€” Generates next actions and required inputs for case preparation

**Outputs**:
- `SIGNAL_REPORT` â€” Signal details with urgency score (1-10)
- `SIGNAL_SUMMARY` â€” Human-readable summary
- `AUTOPREP_BUNDLE` â€” Recommended actions + required inputs
- `NEXT_BEST_ACTIONS` â€” Actionable next steps

**Analytical Logic**: Signal retrieval from SQLite + approved external feeds, structured summarization, relevance filters, semantic grounding.

**Example**: Detects contract expiring in 35 days â†’ Urgency score 7 â†’ Recommends "Review contract terms" + "Evaluate alternatives"

---

### 3. Supplier Scoring Agent

**Purpose**: Converts human-defined evaluation criteria into structured score inputs; processes historical performance and risk data.

**Key Responsibilities**:
- Build evaluation criteria from inputs
- Pull supplier performance data
- Pull risk indicators
- Normalize metrics for comparison
- Compute weighted scores and ranking
- Check eligibility against rules
- Generate explanations

**Sub-Tasks**:
1. **`build_evaluation_criteria`** â€” Constructs criteria from user inputs + templates (weights, descriptions)
2. **`pull_supplier_performance`** â€” Retrieves performance KPIs from SQLite (quality, delivery, responsiveness, cost variance)
3. **`pull_risk_indicators`** â€” Gets SLA events, breach counts, severity from SQLite
4. **`normalize_metrics`** â€” Normalizes all metrics to 0-10 scale for fair comparison
5. **`compute_scores_and_rank`** â€” Calculates weighted scores using criteria weights, ranks suppliers
6. **`eligibility_checks`** â€” Applies rule-based thresholds (min score, max breaches, required capabilities)
7. **`generate_explanations`** â€” LLM narration explaining why suppliers scored as they did

**Outputs**:
- `EVALUATION_SCORECARD` â€” Criteria and weights used
- `SUPPLIER_SCORECARD` â€” Scored table with all suppliers + ranking
- `SUPPLIER_SHORTLIST` â€” Top N suppliers with rationale

**Analytical Logic**: Deterministic scoring formulas, ML performance normalization (optional), rule-based eligibility checks, explanatory generation.

**Example**: Evaluates 3 suppliers â†’ SUP-001 scores 7.8/10 (best) â†’ SUP-002 scores 7.2/10 â†’ SUP-003 scores 8.2/10 but has eligibility issues â†’ Shortlist: SUP-001, SUP-003

---

### 4. RFx Draft Agent

**Purpose**: Assembles RFx drafts using templates, past examples, and structured generation based on sourcing manager inputs.

**Key Responsibilities**:
- Determine RFx path (RFI/RFP/RFQ)
- Retrieve templates and past examples
- Assemble document sections
- Check completeness
- Draft questions and requirements
- Create Q&A tracker

**Sub-Tasks**:
1. **`determine_rfx_path`** â€” Rules-based selection: RFI if requirements undefined, RFQ if <$50K and specs complete, RFP otherwise
2. **`retrieve_templates_and_past_examples`** â€” Searches ChromaDB for RFx templates and past examples by category
3. **`assemble_rfx_sections`** â€” Builds standard sections (Executive Summary, Scope, Technical Requirements, Pricing, etc.)
4. **`completeness_checks`** â€” Rule-based validation: all required sections present, no placeholder content
5. **`draft_questions_and_requirements`** â€” LLM generation of key questions grounded in templates
6. **`create_qa_tracker`** â€” Creates structured Q&A tracking table for supplier responses

**Outputs**:
- `RFX_PATH` â€” Determined path (RFI/RFP/RFQ) with rationale
- `RFX_DRAFT_PACK` â€” Complete draft document with sections
- `RFX_QA_TRACKER` â€” Q&A tracking table

**Analytical Logic**: Template assembly, retrieval of past RFx materials, controlled narrative generation, rule-based completeness checks.

**Example**: Category IT Services, $450K value â†’ Determines RFP path â†’ Retrieves IT Services RFP template â†’ Assembles 7 sections â†’ Completeness 85% â†’ Generates 5 key questions â†’ Creates tracker

---

### 5. Negotiation Support Agent

**Purpose**: Highlights bid differences, identifies negotiation levers, provides structured insights **WITHOUT making award decisions**.

**Key Responsibilities**:
- Compare supplier bids
- Extract leverage points
- Retrieve market benchmarks
- Detect price anomalies
- Propose targets and fallbacks
- Generate negotiation playbook

**Sub-Tasks**:
1. **`compare_bids`** â€” Structured comparison of bids (price, terms, SLA, services) with variance calculations
2. **`leverage_point_extraction`** â€” Identifies negotiation leverage from performance data and competitive alternatives
3. **`benchmark_retrieval`** â€” Searches ChromaDB for market rate benchmarks and industry standards
4. **`price_anomaly_detection`** â€” Statistical analysis to flag unusually high/low bids (>20% from mean)
5. **`propose_targets_and_fallbacks`** â€” Calculates target price (5% below lowest), fallback (lowest bid), walk-away (10% above lowest)
6. **`negotiation_playbook`** â€” LLM generation of talking points, give/get trades, closing techniques

**Outputs**:
- `NEGOTIATION_PLAN` â€” Targets, fallbacks, playbook summary
- `LEVERAGE_SUMMARY` â€” Identified leverage points with strength ratings
- `TARGET_TERMS` â€” Specific target values for key terms

**Analytical Logic**: Structured bid comparison, price anomaly detection, benchmark retrieval, negotiation heuristics.

**Example**: 3 bids received â†’ Price spread 5.6% â†’ Identifies competition leverage â†’ Target: $427,500 (5% below lowest) â†’ Fallback: $450,000 â†’ Walk-away: $495,000 â†’ Generates playbook with talking points

---

### 6. Contract Support Agent

**Purpose**: Extracts key award terms and prepares structured inputs for contracting and implementation.

**Key Responsibilities**:
- Extract key terms from documents
- Validate terms against policy
- Summarize term alignment
- Create implementation handoff packet

**Sub-Tasks**:
1. **`extract_key_terms`** â€” Retrieves contract documents from ChromaDB, extracts structured terms (pricing, term, SLA, liability, termination)
2. **`term_validation`** â€” Rule-based checks against policy (liability limits, SLA minimums, cure periods, payment terms)
3. **`term_alignment_summary`** â€” LLM narration summarizing term alignment and any issues
4. **`implementation_handoff_packet`** â€” Creates structured handoff with contract summary, contacts, SLA summary, payment schedule, critical dates, risk items

**Outputs**:
- `KEY_TERMS_EXTRACT` â€” Structured extraction of all key terms
- `TERM_VALIDATION_REPORT` â€” Validation results with issues flagged
- `CONTRACT_HANDOFF_PACKET` â€” Complete handoff for implementation team

**Analytical Logic**: Template-guided extraction, rule-based contract field validation, knowledge graph grounding (optional), term alignment.

**Example**: Extracts terms from contract doc â†’ Validates: liability OK, SLA 99.5% OK, payment Net 30 OK â†’ 1 issue: termination clause missing â†’ Creates handoff with all details

---

### 7. Implementation Agent

**Purpose**: Produces rollout steps and early post-award indicators (savings + service impacts).

**Key Responsibilities**:
- Build rollout checklist
- Compute expected savings
- Define early success indicators
- Generate reporting templates

**Sub-Tasks**:
1. **`build_rollout_checklist`** â€” Retrieves rollout playbooks from ChromaDB, creates phased checklist (Preparation, Kick-off, Transition, Steady State)
2. **`compute_expected_savings`** â€” Deterministic calculations: annual savings = old value - new value, total = annual Ã— term years, breakdown (hard 70%, soft 20%, avoidance 10%)
3. **`define_early_indicators`** â€” Defines KPIs for early monitoring (SLA compliance, response time, delivery, invoice accuracy, satisfaction) with risk triggers
4. **`reporting_templates`** â€” Generates structured templates for monthly reports, quarterly reviews, savings tracking

**Outputs**:
- `IMPLEMENTATION_CHECKLIST` â€” Phased rollout checklist with owners and dates
- `EARLY_INDICATORS_REPORT` â€” KPI definitions with targets and risk triggers
- `VALUE_CAPTURE_TEMPLATE` â€” Savings breakdown and reporting templates

**Analytical Logic**: Deterministic calculations, retrieval of rollout playbooks, structured reporting templates.

**Example**: Contract value $450K (old $500K) â†’ Annual savings $50K (10%) â†’ Total $150K over 3 years â†’ Creates 4-phase checklist (90 days) â†’ Defines 5 KPIs â†’ Sets up monthly/quarterly templates

---

## ğŸ”„ Task Execution Flow

All sub-tasks follow the same execution hierarchy:

```
Task.execute(context)
  â†“
1. run_rules(context)
   â†’ Deterministic checks, policy validation
   â†’ May short-circuit if rules block execution
  â†“
2. run_retrieval(context, rules_result)
   â†’ Query ChromaDB for documents
   â†’ Query SQLite for structured data
   â†’ Build grounding references
  â†“
3. run_analytics(context, rules_result, retrieval_result)
   â†’ Compute scores, normalize metrics
   â†’ Compare, rank, detect anomalies
   â†’ Apply eligibility rules
  â†“
4. run_llm(context, rules_result, retrieval_result, analytics_result)
   â†’ Only if needs_llm_narration() returns True
   â†’ Generate narrative summaries
   â†’ Create explanations
  â†“
TaskResult(data, grounded_in, tokens_used)
```

**Key Principles**:
- **Rules first** â€” Never call LLM if rules block
- **Retrieval second** â€” Always ground in data before analysis
- **Analytics third** â€” Use deterministic calculations when possible
- **LLM last** â€” Only for narration/packaging, not decision-making

---

## ğŸ“ Data

Synthetic test data:
- **CASE-0001** â€” IT Services contract renewal scenario
- **3 Suppliers** â€” Performance data with differentiation
- **12 months spend** â€” With anomaly detection
- **SLA events** â€” Supplier performance issues
- **Sample documents** â€” RFP template, benchmarks, policy, contract terms

Seed via: `python backend/scripts/seed_synthetic_data.py`

---

## âš ï¸ Notes

- **Research POC** â€” Not production-ready
- **Synthetic data** â€” All metrics are illustrative
- **No authentication** â€” Add API keys for production
- **Backward compatible** â€” Legacy agents still work alongside new system

---

## ğŸ“œ License

Research POC â€” Not for production use

---

## ğŸ› ï¸ Development Status

| Component | Status |
|-----------|--------|
| 7 Official Agents | âœ… Complete |
| Task System | âœ… Complete |
| Artifact System | âœ… Complete |
| Procurement Workbench UI | âœ… Complete |
| Synthetic Data & Demo | âœ… Complete |
| Production Hardening | ğŸ”œ Planned |
